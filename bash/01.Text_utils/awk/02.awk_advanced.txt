
--------------------------------------------------------------------------------------
##speedup processing by dropping unicode support
$ LC_ALL=C awk '{ groups[$0]++ }'

##extract uniq lines without sort
$ awk '!seen[$0]++'

##print duplicates (without sort):
$ awk '++seen[$0] == 2'
Print the 2nd time you see a string.

##Group counts or sums
$ awk '{ groups[$0]++ }     END { for (k in groups) print groups[k], k }' # count
$ awk '{ groups[$1] += $2 } END { for (k in groups) print groups[k], k }' # sum

##Set operations: union, intersection, difference

##Union
$cat all the files and use the “uniq without sort” recipe from above

##Intersection
For both intersection and difference, you need to accumulate from one file and process the other file.
$ awk 'NR == FNR {lut[$0] = 1; next} $0 in lut {print}' FILE1 FILE2

##Difference
$ awk 'NR == FNR {lut[$0] = 1; next} !($0 in lut) {print}' FILE1 FILE2

This operation isn’t symmetrical: you’re removing the entries from FILE1 from FILE2. Switch the files around to get the other set difference.


--------------------------------------------------------------------------------------
##Misc Ref
https://linuxhandbook.com/awk-command-tutorial/
https://github.com/freznicek/awesome-awk
https://catonmat.net/ten-awk-tips-tricks-and-pitfalls
https://backreference.org/2010/04/17/csv-parsing-with-awk/

##Simplification with equivalents

condition { actions }
awk '{if ($0 ~ /pattern/) print $0}'
awk '$0 ~ /pattern/ {print $0}'
awk '/pattern/ {print}'
awk '/pattern/ {print}'
awk '/pattern/'
awk '(NR%2 && /pattern/) || (!(NR%2) && /anotherpattern/)'
prints odd lines that match /pattern/, or even lines that match /

--------------------------------------------------------------------------------------
##Conditional use cases

awk 'NR % 6'            # prints all lines except those divisible by 6
awk 'NR > 5'            # prints from line 6 onwards (like tail -n +6, or sed '1,5d')
awk '$2 == "foo"'       # prints lines where the second field is "foo"
awk 'NF >= 6'           # prints lines with 6 or more fields
awk '/foo/ && /bar/'    # prints lines that match /foo/ and /bar/, in any order
awk '/foo/ && !/bar/'   # prints lines that match /foo/ but not /bar/
awk '/foo/ || /bar/'    # prints lines that match /foo/ or /bar/ (like grep -e 'foo' -e 'bar')
awk '/foo/,/bar/'       # prints from line matching /foo/ to line matching /bar/, inclusive
awk 'NF'                # prints only nonempty lines (or: removes empty lines, where NF==0)
awk 'NF--'              # removes last field and prints the line
awk '$0 = NR" "$0'      # prepends line numbers (assignments are valid in conditions)
--------------------------------------------------------------------------------------
# prints lines that are both in file1 and file2 (intersection)
awk 'NR==FNR{a[$0];next} $0 in a' file1 file2

##Map a data file
--data file
20081010 1123 xxx
20081011 1234 def
20081012 0933 xyz
20081013 0512 abc
20081013 0717 def

--map file
abc withdrawal
def payment
xyz deposit
xxx balance

# use information from a map file to modify a data file
awk 'NR==FNR{a[$1]=$2;next} {$3=a[$3]}1' mapfile datafile

--------------------------------------------------------------------------------------
##Print lines using ranges

# prints lines from /beginpat/ to /endpat/, inclusive
awk '/beginpat/,/endpat/'

# prints lines from /beginpat/ to /endpat/, not inclusive
awk '/beginpat/,/endpat/{if (!/beginpat/&&!/endpat/)print}'

# prints lines from /beginpat/ to /endpat/, not including /beginpat/
awk '/beginpat/,/endpat/{if (!/beginpat/)print}'


--------------------------------------------------------------------------------------
##Admin tools

##Identify all processes that have been running for more than 24 hours

The sort -etimes option will also sort them starting with the longest running process
# You can replace 24*3600 by the number of seconds, inside the if command
ps -eo etimes,pid,lstart,etime,args --sort -etimes | awk '{if ($1 > 24*3600) print $0 }'


--------------------------------------------------------------------------------------




--------------------------------------------------------------------------------------

--------------------------------------------------------------------------------------

--------------------------------------------------------------------------------------






